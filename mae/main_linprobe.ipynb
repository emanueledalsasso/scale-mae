{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import kornia.augmentation as K\n",
    "import numpy as np\n",
    "import timm\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms as tv_transforms\n",
    "import wandb\n",
    "import yaml\n",
    "from kornia.augmentation import AugmentationSequential\n",
    "from kornia.constants import Resample\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from wandb_log import WANDB_LOG_IMG_CONFIG\n",
    "\n",
    "import models_vit\n",
    "import models_mae\n",
    "import models_vit_segmentation\n",
    "import util.lr_decay as lrd\n",
    "import util.misc as misc\n",
    "#from dataloaders.utils import get_dataset_and_sampler, get_eval_dataset_and_transform\n",
    "from engine_finetune import evaluate, train_one_epoch\n",
    "from lib.transforms import CustomCompose\n",
    "from PIL import Image\n",
    "from timm.models.layers import trunc_normal_\n",
    "from util.lars import LARS\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "from marinedebrisdetector.marinedebrisdetector.data.marinedebrisdatamodule import MarineDebrisDataModule\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        \"MAE linear probing for image classification\", add_help=False\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint_interval\", default=20, type=int, help=\"How often to checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=64,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--print_freq\",\n",
    "        default=20,\n",
    "        type=int,\n",
    "        help=\"How often (iters) print results to wandb\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--drop_path\",\n",
    "        type=float,\n",
    "        default=0.1,\n",
    "        metavar=\"PCT\",\n",
    "        help=\"Drop path rate (default: 0.1)\",\n",
    "    )\n",
    "    parser.add_argument(\"--epochs\", default=400, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--accum_iter\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"Accumulate gradient iterations (for increasing the effective batch size under memory constraints)\",\n",
    "    )\n",
    "    parser.add_argument(\"--config\", default=\"config.yaml\", type=str, help=\"Config file\")\n",
    "    parser.add_argument(\"--name\", default=\"\", type=str, help=\"Name of wandb entry\")\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        default=\"vit_large_patch16\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of model to train\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--linear_layer_scale\", default=1.0, type=float, help=\"\")\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--wandb_id\", default=None, type=str, help=\"Wandb id, useful for resuming runs\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--input_size\", default=128, type=int, help=\"images input size\")\n",
    "    parser.add_argument(\n",
    "        \"--target_size\", nargs=\"*\", type=int, help=\"images input size\", default=[128]\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--source_size\", nargs=\"*\", type=int, help=\"images source size\", default=[128]\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--mask_ratio\",\n",
    "        default=0.75,\n",
    "        type=float,\n",
    "        help=\"Masking ratio (percentage of removed patches).\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--scale_min\", default=0.5, type=float, help=\"Min RRC scale\")\n",
    "\n",
    "    parser.add_argument(\"--scale_max\", default=1.0, type=float, help=\"Max RRC scale\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--norm_pix_loss\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Use (per-patch) normalized pixels as targets for computing loss\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--restart\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Load the checkpoint, but start from epoch 0\",\n",
    "    )\n",
    "    parser.set_defaults(norm_pix_loss=False)\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument(\n",
    "        \"--weight_decay\", type=float, default=0.05, help=\"weight decay (default: 0.05)\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        default=None,\n",
    "        metavar=\"LR\",\n",
    "        help=\"learning rate (absolute lr)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--blr\",\n",
    "        type=float,\n",
    "        default=1e-3,\n",
    "        metavar=\"LR\",\n",
    "        help=\"base learning rate: absolute_lr = base_lr * total_batch_size / 256\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--layer_decay\",\n",
    "        type=float,\n",
    "        default=0.75,\n",
    "        help=\"layer-wise lr decay from ELECTRA/BEiT\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min_lr\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        metavar=\"LR\",\n",
    "        help=\"lower lr bound for cyclic schedulers that hit 0\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--warmup_epochs\", type=int, default=0, metavar=\"N\", help=\"epochs to warmup LR\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        default=\"./output_dir\",\n",
    "        help=\"path where to save, empty for no saving\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--log_dir\", default=\"./output_dir\", help=\"path where to tensorboard log\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--eval_only\", action=\"store_true\", help=\"Only do KNN Eval\")\n",
    "    parser.add_argument(\n",
    "        \"--eval_dataset\",\n",
    "        default=\"resisc\",\n",
    "        type=str,\n",
    "        help=\"name of eval dataset to use. Options are resisc (default), airound, mlrsnet, and fmow.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_path\", default=\"resisc45\", type=str, help=\"dataset path\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_gsd\",\n",
    "        action=\"store_true\",\n",
    "        help=\"USE GSD Relative Embedding with base=224x224\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_base_resolution\",\n",
    "        default=1.0,\n",
    "        type=float,\n",
    "        help=\"Global Multiplication factor of Positional Embedding Resolution in KNN\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_reference_resolution\",\n",
    "        default=224,\n",
    "        type=float,\n",
    "        help=\"Reference input resolution to scale GSD factor by in eval.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_scale\", default=224, type=int, help=\"The size of the eval input.\"\n",
    "    )\n",
    "    parser.add_argument(\"--eval\", action=\"store_true\", help=\"Perform evaluation only\")\n",
    "    parser.add_argument(\n",
    "        \"--dist_eval\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Enabling distributed evaluation (recommended during training for faster monitor\",\n",
    "    )\n",
    "    parser.set_defaults(eval_only=False)\n",
    "    parser.add_argument(\n",
    "        \"--no_autoresume\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Dont autoresume from last checkpoint\",\n",
    "    )\n",
    "    parser.set_defaults(no_autoresume=False)\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--resume\", default=\"\", help=\"resume from checkpoint\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--start_epoch\", default=0, type=int, metavar=\"N\", help=\"start epoch\"\n",
    "    )\n",
    "    parser.add_argument(\"--num_workers\", default=10, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "    parser.add_argument(\"--no_pin_mem\", action=\"store_false\", dest=\"pin_mem\")\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument(\n",
    "        \"--world_size\", default=1, type=int, help=\"number of distributed processes\"\n",
    "    )\n",
    "    parser.add_argument(\"--local_rank\", default=-1, type=int)\n",
    "    parser.add_argument(\"--dist_on_itp\", action=\"store_true\")\n",
    "    parser.add_argument(\n",
    "        \"--dist_url\", default=\"env://\", help=\"url used to set up distributed training\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--base_resolution\",\n",
    "        default=2.5,\n",
    "        type=float,\n",
    "        help=\"The base resolution to use for the period of the sin wave for positional embeddings\",\n",
    "    )\n",
    "\n",
    "    # * Finetuning params\n",
    "    parser.add_argument(\n",
    "        \"--finetune\",\n",
    "        default=True,\n",
    "        help=\"If true, finetune. If false, linear probe.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint_path\", default='/home/emanuele/jobs/adopt/scale-MAE-marinelitter/IGARSS2024/scalemae-vitlarge-800.pth', type=str, help=\"Path to checkpoint weights.\"\n",
    "    )\n",
    "    parser.add_argument(\"--global_pool\", action=\"store_true\")\n",
    "    parser.set_defaults(global_pool=False)\n",
    "    parser.add_argument(\n",
    "        \"--cls_token\",\n",
    "        action=\"store_false\",\n",
    "        dest=\"global_pool\",\n",
    "        help=\"Use class token instead of global pool for classification\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--nb_classes\",\n",
    "        default=1000,\n",
    "        type=int,\n",
    "        help=\"number of the classification types\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument('--data-path', type=str, default=\"/home/emanuele/data/ADOPT/marinedebris\")\n",
    "    parser.add_argument('--image-size', type=int, default=128)\n",
    "    parser.add_argument('--download', action=\"store_false\")\n",
    "    parser.add_argument('--no-label-refinement', action=\"store_false\")\n",
    "    parser.add_argument('--no-s2ships', action=\"store_false\")\n",
    "    parser.add_argument('--no-marida', action=\"store_true\")\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args_parser()\n",
    "args = args.parse_args()\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n"
     ]
    }
   ],
   "source": [
    "misc.init_distributed_mode(args)\n",
    "num_tasks = misc.get_world_size()\n",
    "global_rank = misc.get_rank()\n",
    "\n",
    "#print(f\"job dir: {os.path.dirname(os.path.realpath(__file__))}\")\n",
    "#print(f\"{args}\".replace(\", \", \",\\n\"))\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# fix the seed for reproducibility\n",
    "seed = args.seed + misc.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## backwards compatability hacks\n",
    "if not isinstance(args.target_size, list):\n",
    "    args.target_size = [args.target_size]\n",
    "\n",
    "if not isinstance(args.source_size, list):\n",
    "    args.source_size = [args.source_size]\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that all sizes in target_size are multiples of 16\n",
    "if len(args.target_size) > 0:\n",
    "    assert all(\n",
    "        [type(i) == int for i in args.target_size]\n",
    "    ), \"Invalid multiscale input, it should be a json list of int, e.g. [224,448]\"\n",
    "    assert all(\n",
    "        [i % 16 == 0 for i in args.target_size]\n",
    "    ), \"Decoder resolution must be a multiple of patch size (16)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random wandb id before fixing random seeds\n",
    "random_wandb_id = wandb.util.generate_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Composition total\n",
      "\n",
      "train\n",
      "flobs_dataset (train): 39194\n",
      "shipsdataset: 29833\n",
      "MARIDA (train): 2017\n",
      "\n",
      "val\n",
      "refinedflobs_val: 2451\n",
      "MARIDA (val): 1185\n",
      "\n",
      "test\n",
      "flobstestdataset: 2197\n",
      "maridatestdataset: 872\n",
      "\n",
      "\n",
      "Dataset Composition debris/non-debris\n",
      "train \n",
      "flobs_dataset (train): 19587/19607\n",
      "shipsdataset: 0/29833\n",
      "MARIDA (train): 930/1087\n",
      "\n",
      "val\n",
      "refinedflobs_val: 868/1583\n",
      "MARIDA (val): 616/569\n",
      "\n",
      "test\n",
      "flobstestdataset: 903/1294\n",
      "maridatestdataset: 270/602\n"
     ]
    }
   ],
   "source": [
    "marinedebris_datamodule = MarineDebrisDataModule(data_root=args.data_path,\n",
    "                                        image_size=args.image_size,\n",
    "                                        workers=args.num_workers,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        no_label_refinement=args.no_label_refinement,\n",
    "                                        no_s2ships=args.no_s2ships,\n",
    "                                        no_marida=args.no_marida,\n",
    "                                        download=False)\n",
    "\n",
    "marinedebris_datamodule.prepare_data()\n",
    "marinedebris_datamodule.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = marinedebris_datamodule.train_dataloader()\n",
    "data_loader_val = marinedebris_datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for image, mask, _ in data_loader_val:\\n    print(image.shape)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for image, mask, _ in data_loader_val:\n",
    "    print(image.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean_ndvi = 0\\nmean_fdi = 0\\nmean_grayscale = 0\\nx2_ndvi = 0\\nx2_fdi = 0\\nx2_grayscale = 0\\ni = 0\\n\\nfor image, mask, _ in dataset_train:\\n    print(i)\\n    i += 1\\n    grayscale = image[0]\\n    fdi = image[1]\\n    ndvi = image[2]\\n    mean_ndvi += torch.mean(ndvi)\\n    mean_fdi += torch.mean(fdi)\\n    mean_grayscale += torch.mean(grayscale)\\n    x2_ndvi += torch.sum(ndvi**2)\\n    x2_fdi += torch.sum(fdi**2)\\n    x2_grayscale += torch.sum(ndvi**2)\\nmean_ndvi = mean_ndvi/i\\nmean_fdi = mean_fdi/i\\nmean_grayscale = mean_grayscale/i\\nstd_ndvi = torch.sqrt(x2_ndvi/(i*128*128)-mean_ndvi**2)\\nstd_fdi = torch.sqrt(x2_fdi/(i*128*128)-mean_fdi**2)\\nstd_greyscale = torch.sqrt(x2_grayscale/(i*128*128)-mean_grayscale**2)\\nprint(mean_grayscale)\\nprint(mean_ndvi)\\nprint(mean_fdi)\\nprint(std_greyscale)\\nprint(std_ndvi)\\nprint(std_fdi)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_image = next(iter(dataset_train))\n",
    "\n",
    "\"\"\"mean_ndvi = 0\n",
    "mean_fdi = 0\n",
    "mean_grayscale = 0\n",
    "x2_ndvi = 0\n",
    "x2_fdi = 0\n",
    "x2_grayscale = 0\n",
    "i = 0\n",
    "\n",
    "for image, mask, _ in dataset_train:\n",
    "    print(i)\n",
    "    i += 1\n",
    "    grayscale = image[0]\n",
    "    fdi = image[1]\n",
    "    ndvi = image[2]\n",
    "    mean_ndvi += torch.mean(ndvi)\n",
    "    mean_fdi += torch.mean(fdi)\n",
    "    mean_grayscale += torch.mean(grayscale)\n",
    "    x2_ndvi += torch.sum(ndvi**2)\n",
    "    x2_fdi += torch.sum(fdi**2)\n",
    "    x2_grayscale += torch.sum(ndvi**2)\n",
    "mean_ndvi = mean_ndvi/i\n",
    "mean_fdi = mean_fdi/i\n",
    "mean_grayscale = mean_grayscale/i\n",
    "std_ndvi = torch.sqrt(x2_ndvi/(i*128*128)-mean_ndvi**2)\n",
    "std_fdi = torch.sqrt(x2_fdi/(i*128*128)-mean_fdi**2)\n",
    "std_greyscale = torch.sqrt(x2_grayscale/(i*128*128)-mean_grayscale**2)\n",
    "print(mean_grayscale)\n",
    "print(mean_ndvi)\n",
    "print(mean_fdi)\n",
    "print(std_greyscale)\n",
    "print(std_ndvi)\n",
    "print(std_fdi)\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset_train = marinedebris_datamodule.train_dataloader()\\nsampler_train = torch.utils.data.DistributedSampler(\\n            dataset_train, num_replicas=num_tasks, rank=global_rank, shuffle=True\\n        )\\nbatch_size_factor = 1\\ndata_loader_train = torch.utils.data.DataLoader(\\n        dataset_train,\\n        sampler=sampler_train,\\n        batch_size=int(args.batch_size * batch_size_factor),\\n        num_workers=args.num_workers,\\n        pin_memory=args.pin_mem,\\n        drop_last=True,\\n    )\\ndataset_val = marinedebris_datamodule.val_dataloader()\\nsampler_val = torch.utils.data.DistributedSampler(\\n        dataset_val,\\n        num_replicas=num_tasks,\\n        rank=global_rank,\\n        shuffle=False,\\n        drop_last=False,\\n    )\\ndata_loader_val = torch.utils.data.DataLoader(\\n        dataset_val,\\n        batch_size=args.batch_size,\\n        sampler=sampler_val,\\n        num_workers=args.num_workers,\\n    )'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dataset_train = marinedebris_datamodule.train_dataloader()\n",
    "sampler_train = torch.utils.data.DistributedSampler(\n",
    "            dataset_train, num_replicas=num_tasks, rank=global_rank, shuffle=True\n",
    "        )\n",
    "batch_size_factor = 1\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        sampler=sampler_train,\n",
    "        batch_size=int(args.batch_size * batch_size_factor),\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "    )\n",
    "dataset_val = marinedebris_datamodule.val_dataloader()\n",
    "sampler_val = torch.utils.data.DistributedSampler(\n",
    "        dataset_val,\n",
    "        num_replicas=num_tasks,\n",
    "        rank=global_rank,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=sampler_val,\n",
    "        num_workers=args.num_workers,\n",
    "    )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = models_mae.__dict__['mae_'+args.model](\\n    fixed_output_size = 0\\n)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models_vit.__dict__[args.model](\n",
    "    img_size=args.input_size,\n",
    "    num_classes=args.nb_classes,\n",
    "    global_pool=args.global_pool,\n",
    ")\n",
    "'''model = models_vit_segmentation.__dict__[args.model](\n",
    "    img_size=args.input_size,\n",
    "    num_classes=args.nb_classes,\n",
    "    global_pool=args.global_pool,\n",
    ")'''\n",
    "'''model = models_mae.__dict__['mae_'+args.model](\n",
    "    fixed_output_size = 0\n",
    ")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Load pre-trained checkpoint from: /home/emanuele/jobs/adopt/scale-MAE-marinelitter/IGARSS2024/scalemae-vitlarge-800.pth\n",
      "Removing key pos_embed from pretrained checkpoint\n",
      "_IncompatibleKeys(missing_keys=['pos_embed', 'head.weight', 'head.bias'], unexpected_keys=['mask_token', 'decoder_pos_embed', 'decoder_embed.weight', 'decoder_embed.bias', 'fpn.fpn1.0.weight', 'fpn.fpn1.0.bias', 'fpn.fpn1.1.ln.weight', 'fpn.fpn1.1.ln.bias', 'fpn.fpn1.3.weight', 'fpn.fpn1.3.bias', 'fpn.fpn2.0.weight', 'fpn.fpn2.0.bias', 'fcn_high.proj.weight', 'fcn_high.proj.bias', 'fcn_high.conv_blocks.0.convs.1.weight', 'fcn_high.conv_blocks.0.convs.1.bias', 'fcn_high.conv_blocks.0.convs.3.weight', 'fcn_high.conv_blocks.0.convs.3.bias', 'fcn_high.conv_blocks.0.residual.weight', 'fcn_high.conv_blocks.0.residual.bias', 'fcn_high.conv_blocks.1.convs.1.weight', 'fcn_high.conv_blocks.1.convs.1.bias', 'fcn_high.conv_blocks.1.convs.3.weight', 'fcn_high.conv_blocks.1.convs.3.bias', 'fcn_high.conv_blocks.1.residual.weight', 'fcn_high.conv_blocks.1.residual.bias', 'fcn_high.pred.0.ln.weight', 'fcn_high.pred.0.ln.bias', 'fcn_high.pred.1.weight', 'fcn_high.pred.1.bias', 'fcn_high.pred.3.weight', 'fcn_high.pred.3.bias', 'fcn_high.pred.5.weight', 'fcn_high.pred.5.bias', 'fcn_high.pred.7.weight', 'fcn_high.pred.7.bias', 'fcn_low.proj.weight', 'fcn_low.proj.bias', 'fcn_low.conv_blocks.0.convs.1.weight', 'fcn_low.conv_blocks.0.convs.1.bias', 'fcn_low.conv_blocks.0.convs.3.weight', 'fcn_low.conv_blocks.0.convs.3.bias', 'fcn_low.conv_blocks.0.residual.weight', 'fcn_low.conv_blocks.0.residual.bias', 'fcn_low.conv_blocks.1.convs.1.weight', 'fcn_low.conv_blocks.1.convs.1.bias', 'fcn_low.conv_blocks.1.convs.3.weight', 'fcn_low.conv_blocks.1.convs.3.bias', 'fcn_low.conv_blocks.1.residual.weight', 'fcn_low.conv_blocks.1.residual.bias', 'fcn_low.pred.0.ln.weight', 'fcn_low.pred.0.ln.bias', 'fcn_low.pred.1.weight', 'fcn_low.pred.1.bias', 'fcn_low.pred.3.weight', 'fcn_low.pred.3.bias', 'fcn_low.pred.5.weight', 'fcn_low.pred.5.bias', 'fcn_low.pred.7.weight', 'fcn_low.pred.7.bias', 'decoder_blocks.0.norm1.weight', 'decoder_blocks.0.norm1.bias', 'decoder_blocks.0.attn.qkv.weight', 'decoder_blocks.0.attn.qkv.bias', 'decoder_blocks.0.attn.proj.weight', 'decoder_blocks.0.attn.proj.bias', 'decoder_blocks.0.norm2.weight', 'decoder_blocks.0.norm2.bias', 'decoder_blocks.0.mlp.fc1.weight', 'decoder_blocks.0.mlp.fc1.bias', 'decoder_blocks.0.mlp.fc2.weight', 'decoder_blocks.0.mlp.fc2.bias', 'decoder_blocks.1.norm1.weight', 'decoder_blocks.1.norm1.bias', 'decoder_blocks.1.attn.qkv.weight', 'decoder_blocks.1.attn.qkv.bias', 'decoder_blocks.1.attn.proj.weight', 'decoder_blocks.1.attn.proj.bias', 'decoder_blocks.1.norm2.weight', 'decoder_blocks.1.norm2.bias', 'decoder_blocks.1.mlp.fc1.weight', 'decoder_blocks.1.mlp.fc1.bias', 'decoder_blocks.1.mlp.fc2.weight', 'decoder_blocks.1.mlp.fc2.bias', 'decoder_blocks.2.norm1.weight', 'decoder_blocks.2.norm1.bias', 'decoder_blocks.2.attn.qkv.weight', 'decoder_blocks.2.attn.qkv.bias', 'decoder_blocks.2.attn.proj.weight', 'decoder_blocks.2.attn.proj.bias', 'decoder_blocks.2.norm2.weight', 'decoder_blocks.2.norm2.bias', 'decoder_blocks.2.mlp.fc1.weight', 'decoder_blocks.2.mlp.fc1.bias', 'decoder_blocks.2.mlp.fc2.weight', 'decoder_blocks.2.mlp.fc2.bias', 'decoder_norm.weight', 'decoder_norm.bias'])\n"
     ]
    }
   ],
   "source": [
    "if args.checkpoint_path:\n",
    "    checkpoint = torch.load(args.checkpoint_path, map_location=\"cpu\")\n",
    "    print('done')\n",
    "\n",
    "    print(f\"Load pre-trained checkpoint from: {args.checkpoint_path}\")\n",
    "    checkpoint_model = checkpoint[\"model\"]\n",
    "    state_dict = model.state_dict()\n",
    "    for k in [\"head.weight\", \"head.bias\"]:\n",
    "        if (\n",
    "            k in checkpoint_model\n",
    "            and checkpoint_model[k].shape != state_dict[k].shape\n",
    "        ):\n",
    "            print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "            del checkpoint_model[k]\n",
    "    if args.input_size != 224:\n",
    "        if (\n",
    "            \"pos_embed\" in checkpoint_model\n",
    "            and checkpoint_model[\"pos_embed\"].shape != state_dict[\"pos_embed\"].shape\n",
    "        ):\n",
    "            print(f\"Removing key pos_embed from pretrained checkpoint\")\n",
    "            del checkpoint_model[\"pos_embed\"]\n",
    "\n",
    "    # interpolate position embedding\n",
    "    # We do not do this in Scale-MAE since we use a resolution-specific\n",
    "    # pos embedding in forward_features\n",
    "    # interpolate_pos_embed(model, checkpoint_model)\n",
    "\n",
    "    # load pre-trained model\n",
    "    msg = model.load_state_dict(checkpoint_model, strict=False)\n",
    "    print(msg)\n",
    "\n",
    "    if args.global_pool:\n",
    "        assert set(msg.missing_keys) == {\n",
    "            \"head.weight\",\n",
    "            \"head.bias\",\n",
    "            \"fc_norm.weight\",\n",
    "            \"fc_norm.bias\",\n",
    "        }\n",
    "    else:\n",
    "        if args.input_size != 224:\n",
    "            assert set(msg.missing_keys) == {\n",
    "                \"head.weight\",\n",
    "                \"head.bias\",\n",
    "                \"pos_embed\",\n",
    "            }\n",
    "        else:\n",
    "            assert set(msg.missing_keys) == {\"head.weight\", \"head.bias\"}\n",
    "\n",
    "    if not args.eval:\n",
    "        # manually initialize fc layer: following MoCo v3\n",
    "        trunc_normal_(model.head.weight, std=0.01)\n",
    "        # model.head.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "out_chans = 1 # number of feature maps projected\n",
    "'''model.head = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.head.in_features, patch_size**2 * out_chans, bias=True),\n",
    "    torch.nn.Conv2d(in_channels=model.head.in_features, out_channels=32, kernel_size=1, stride=1,\n",
    "                                    padding='same'), torch.nn.LeakyReLU(0.1), torch.nn.Conv2d(in_channels=32, out_channels=16, kernel_size=1, stride=1,\n",
    "                                    padding='same'), torch.nn.LeakyReLU(0.1),torch.nn.Conv2d(in_channels=16, out_channels=1, kernel_size=1, stride=1,\n",
    "                                    padding='same')\n",
    ")'''\n",
    "model.head = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.head.in_features, patch_size**2 * out_chans, bias=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbedUnSafe(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-23): 24 x Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not args.finetune:\n",
    "    # Linear probe\n",
    "    # freeze all but the head\n",
    "    for _, p in model.named_parameters():\n",
    "        p.requires_grad = False\n",
    "    for _, p in model.head.named_parameters():\n",
    "        p.requires_grad = True\n",
    "else:\n",
    "    for _, p in model.named_parameters():\n",
    "        p.requires_grad = True\n",
    "    for _, p in model.head.named_parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# ScaleMAE does not use the pos_embed within ViT\n",
    "model.pos_embed.requires_grad = False\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_ddp = model\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0007525434581650003\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0007525434581650003\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 2\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0010033912775533338\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 3\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0010033912775533338\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 4\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0013378550367377784\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 5\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0013378550367377784\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 6\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0017838067156503712\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 7\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0017838067156503712\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 8\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.002378408954200495\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 9\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.002378408954200495\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 10\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0031712119389339932\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 11\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.0031712119389339932\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 12\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.004228282585245324\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 13\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.004228282585245324\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 14\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.005637710113660432\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 15\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.005637710113660432\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 16\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.00751694681821391\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 17\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.00751694681821391\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 18\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.010022595757618546\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 19\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.010022595757618546\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 20\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.013363461010158062\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 21\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.013363461010158062\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 22\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.017817948013544083\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 23\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.017817948013544083\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 24\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.023757264018058777\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 25\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.023757264018058777\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 26\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.03167635202407837\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 27\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.03167635202407837\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 28\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.04223513603210449\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 29\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.04223513603210449\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 30\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.056313514709472656\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 31\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.056313514709472656\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 32\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.07508468627929688\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 33\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.07508468627929688\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 34\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.1001129150390625\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 35\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.1001129150390625\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 36\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.13348388671875\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 37\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.13348388671875\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 38\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.177978515625\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 39\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.177978515625\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 40\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.2373046875\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 41\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.2373046875\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 42\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.31640625\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 43\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.31640625\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 44\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.421875\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 45\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.421875\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 46\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.5625\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 47\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.5625\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 48\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.75\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 49\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 0.75\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 50\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 1.0\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 51\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    lr_scale: 1.0\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if args.lr is None:  # only base_lr is specified\n",
    "    args.lr = args.blr * eff_batch_size / 256\n",
    "\n",
    "'''if args.distributed:\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "    model_without_ddp = model.module'''\n",
    "\n",
    "if not args.finetune:\n",
    "    # Linear probe\n",
    "    param_groups = optim_factory.param_groups_layer_decay(\n",
    "        model_without_ddp, args.weight_decay\n",
    "    )\n",
    "else:\n",
    "    # build optimizer with layer-wise lr decay (lrd)\n",
    "    param_groups = lrd.param_groups_lrd(\n",
    "        model_without_ddp,\n",
    "        args.weight_decay,\n",
    "        no_weight_decay_list=model_without_ddp.no_weight_decay(),\n",
    "        layer_decay=args.layer_decay,\n",
    "    )\n",
    "    param_groups[-1][\"lr_scale\"] *= args.linear_layer_scale\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=args.lr, betas=(0.9, 0.95))\n",
    "print(optimizer)\n",
    "loss_scaler = NativeScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = BCEWithLogitsLoss()\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "print(\"criterion = %s\" % str(criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.load_model(\n",
    "    args=args,\n",
    "    model_without_ddp=model_without_ddp,\n",
    "    optimizer=optimizer,\n",
    "    loss_scaler=loss_scaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 128, 128])\n",
      "torch.Size([64, 64, 1024])\n",
      "torch.Size([64, 65, 1024])\n",
      "torch.Size([64, 65, 1024])\n",
      "torch.Size([64, 65, 1024])\n",
      "torch.Size([64, 65, 1024])\n",
      "torch.Size([64, 64, 1024])\n",
      "torch.Size([64, 64, 256])\n",
      "torch.Size([64, 1, 128, 128])\n",
      "torch.Size([64, 1, 128, 128])\n",
      "* loss 0.7056969404220581\n",
      "torch.Size([64, 3, 128, 128])\n",
      "torch.Size([64, 64, 1024])\n",
      "torch.Size([64, 65, 1024])\n",
      "torch.Size([64, 65, 1024])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.69 MiB is free. Process 2480416 has 1.70 GiB memory in use. Including non-PyTorch memory, this process has 21.98 GiB memory in use. Of the allocated memory 19.51 GiB is allocated by PyTorch, and 2.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 50\u001b[0m\n\u001b[1;32m     45\u001b[0m args\u001b[38;5;241m.\u001b[39meval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval:\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_base_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_base_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgsd_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_gsd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_reference_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     exit(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 29\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data_loader, model, device, eval_base_resolution, gsd_embed, eval_scale, reference_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m---> 29\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgsd_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     34\u001b[0m     output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39munpatchify(output,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/scale-mae/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scale-mae/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/adopt/scale-MAE-marinelitter/IGARSS2024/scale-mae/mae/models_vit.py:116\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x, input_res)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, input_res\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 116\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    118\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n",
      "File \u001b[0;32m~/projects/adopt/scale-MAE-marinelitter/IGARSS2024/scale-mae/mae/models_vit.py:99\u001b[0m, in \u001b[0;36mVisionTransformer.forward_features\u001b[0;34m(self, x, input_res)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 99\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_pool:\n",
      "File \u001b[0;32m~/miniconda3/envs/scale-mae/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scale-mae/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/scale-mae/lib/python3.9/site-packages/timm/models/vision_transformer.py:141\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 141\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    142\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)))\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/scale-mae/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scale-mae/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/scale-mae/lib/python3.9/site-packages/timm/models/vision_transformer.py:117\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    114\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv[\u001b[38;5;241m0\u001b[39m], qkv[\u001b[38;5;241m1\u001b[39m], qkv[\u001b[38;5;241m2\u001b[39m]   \u001b[38;5;66;03m# make torchscript happy (cannot use tensor as tuple)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m attn \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[0;32m--> 117\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn)\n\u001b[1;32m    120\u001b[0m x \u001b[38;5;241m=\u001b[39m (attn \u001b[38;5;241m@\u001b[39m v)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B, N, C)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.69 MiB is free. Process 2480416 has 1.70 GiB memory in use. Including non-PyTorch memory, this process has 21.98 GiB memory in use. Of the allocated memory 19.51 GiB is allocated by PyTorch, and 2.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "def evaluate(\n",
    "    data_loader,\n",
    "    model,\n",
    "    device,\n",
    "    eval_base_resolution=1.0,\n",
    "    gsd_embed=False,\n",
    "    eval_scale=512,\n",
    "    reference_size=512,\n",
    "):\n",
    "    gsd_ratio = eval_base_resolution\n",
    "    if gsd_embed:\n",
    "        gsd_ratio = gsd_ratio * (reference_size / eval_scale)\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "    header = \"Test:\"\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for images, target, _ in data_loader:        \n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "        target = target.unsqueeze(1)\n",
    "\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(\n",
    "                images,\n",
    "                input_res=torch.ones(len(images)).float().to(images.device) * gsd_ratio,\n",
    "            )\n",
    "            print(output.shape)\n",
    "            output = model.unpatchify(output,1)\n",
    "            print(output.shape)\n",
    "            print(target.shape)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        #acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "        \n",
    "        print(\"* loss \"+str(loss.item()))\n",
    "\n",
    "\n",
    "args.eval = True\n",
    "\n",
    "\n",
    "\n",
    "if args.eval:\n",
    "    evaluate(\n",
    "        data_loader_train,\n",
    "        model,\n",
    "        device,\n",
    "        eval_base_resolution=args.eval_base_resolution,\n",
    "        gsd_embed=args.eval_gsd,\n",
    "        eval_scale=args.eval_scale,\n",
    "        reference_size=args.eval_reference_resolution,\n",
    "    )\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    data_loader,\n",
    "    model,\n",
    "    device,\n",
    "    eval_base_resolution=1.0,\n",
    "    gsd_embed=False,\n",
    "    eval_scale=512,\n",
    "    reference_size=512,\n",
    "):\n",
    "    gsd_ratio = eval_base_resolution\n",
    "    if gsd_embed:\n",
    "        gsd_ratio = gsd_ratio * (reference_size / eval_scale)\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "    header = \"Test:\"\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for (samples, labels, c) in metric_logger.log_every(data_loader, 10, header):\n",
    "        images = samples\n",
    "        target = labels\n",
    "        c = c\n",
    "        print('c')\n",
    "        print(c.shape)\n",
    "        c = c.to(device, non_blocking=True)\n",
    "        \n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(\n",
    "                images,\n",
    "                input_res=torch.ones(len(images)).float().to(images.device) * gsd_ratio,\n",
    "            )\n",
    "            print(output.shape)\n",
    "            output = model.unpatchify(output,1)\n",
    "            print(output.shape)\n",
    "            print(target.shape)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        #acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "        batch_size = images.shape[0]\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.meters[\"BCE\"].update(loss.item(), n=batch_size)\n",
    "        #metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
    "        #metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
    "    # gather the stats from all processes\n",
    "    # TODO: compute scores for segmentation at this step\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    '''print(\n",
    "        \"* Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f} loss {losses.global_avg:.3f}\".format(\n",
    "            top1=metric_logger.acc1, top5=metric_logger.acc5, losses=metric_logger.loss\n",
    "        )'''\n",
    "    print(\"* loss {losses.global_avg:.3f}\".format(losses=metric_logger.loss)\n",
    "    )\n",
    "\n",
    "    #return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval:\n\u001b[0;32m----> 2\u001b[0m     test_stats \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_base_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_base_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgsd_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_gsd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_reference_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBCE of the network on the test images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBCE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     exit(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 27\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data_loader, model, device, eval_base_resolution, gsd_embed, eval_scale, reference_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m c \u001b[38;5;241m=\u001b[39m c\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     28\u001b[0m c \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "if args.eval:\n",
    "    test_stats = evaluate(\n",
    "        data_loader_val,\n",
    "        model,\n",
    "        device,\n",
    "        eval_base_resolution=args.eval_base_resolution,\n",
    "        gsd_embed=args.eval_gsd,\n",
    "        eval_scale=args.eval_scale,\n",
    "        reference_size=args.eval_reference_resolution,\n",
    "    )\n",
    "    print(\n",
    "        f\"BCE of the network on the test images: {test_stats['BCE']:.1f}%\"\n",
    "    )\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4194304"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*64*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scale-mae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
